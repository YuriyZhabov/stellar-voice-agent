#!/usr/bin/env python3
"""
Validation script for comprehensive test implementation.
Verifies all test components are properly implemented.
"""

import os
import sys
import importlib.util
import ast
from pathlib import Path


class TestImplementationValidator:
    """Validator for test implementation completeness."""
    
    def __init__(self):
        self.test_files = [
            "tests/test_livekit_comprehensive.py",
            "tests/test_livekit_integration_flow.py", 
            "tests/test_livekit_performance_load.py",
            "tests/test_livekit_security_validation.py",
            "tests/test_livekit_api_endpoints.py"
        ]
        
        self.required_components = {
            "unit_tests": [
                "TestLiveKitAuthManager",
                "TestLiveKitAPIClient", 
                "TestLiveKitEgressService",
                "TestLiveKitIngressService",
                "TestLiveKitSystemMonitor",
                "TestLiveKitSecurityManager",
                "TestPerformanceOptimizer",
                "TestLiveKitVoiceAIIntegration"
            ],
            "integration_tests": [
                "TestCompleteCallFlow",
                "TestWebhookIntegrationFlow",
                "TestSIPIntegrationFlow"
            ],
            "performance_tests": [
                "TestPerformanceMetrics",
                "TestLoadTesting", 
                "TestStressTests"
            ],
            "security_tests": [
                "TestJWTTokenSecurity",
                "TestAPIKeySecurity",
                "TestConnectionSecurity",
                "TestAccessControlSecurity",
                "TestDataValidationSecurity",
                "TestSecurityMonitoring"
            ],
            "api_tests": [
                "TestRoomServiceAPI",
                "TestEgressServiceAPI",
                "TestIngressServiceAPI", 
                "TestSIPServiceAPI",
                "TestAPIErrorHandling"
            ]
        }
        
        self.validation_results = {
            "files_exist": {},
            "imports_valid": {},
            "classes_present": {},
            "methods_count": {},
            "overall_status": "unknown"
        }
    
    def validate_file_exists(self, file_path):
        """Validate that test file exists."""
        exists = os.path.exists(file_path)
        self.validation_results["files_exist"][file_path] = exists
        return exists
    
    def validate_imports(self, file_path):
        """Validate that test file can be imported."""
        try:
            spec = importlib.util.spec_from_file_location("test_module", file_path)
            if spec is None:
                return False
            
            module = importlib.util.module_from_spec(spec)
            # Don't actually execute, just check if it can be loaded
            return True
            
        except Exception as e:
            print(f"Import error in {file_path}: {e}")
            return False
    
    def validate_test_classes(self, file_path):
        """Validate test classes are present in file."""
        try:
            with open(file_path, 'r') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            classes_found = []
            methods_count = 0
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    if node.name.startswith('Test'):
                        classes_found.append(node.name)
                        
                        # Count test methods in class
                        for item in node.body:
                            if isinstance(item, ast.FunctionDef) and item.name.startswith('test_'):
                                methods_count += 1
            
            self.validation_results["classes_present"][file_path] = classes_found
            self.validation_results["methods_count"][file_path] = methods_count
            
            return classes_found, methods_count
            
        except Exception as e:
            print(f"AST parsing error in {file_path}: {e}")
            return [], 0
    
    def validate_requirements_coverage(self):
        """Validate that all requirements are covered by tests."""
        
        # Requirements from task specification
        requirements_coverage = {
            "7.1": "System monitoring and diagnostics",
            "8.4": "Security validation and rights",
            "9.3": "Performance optimization"
        }
        
        covered_requirements = set()
        
        # Check each test file for requirement references
        for file_path in self.test_files:
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r') as f:
                        content = f.read()
                    
                    # Look for requirement references in comments/docstrings
                    for req_id in requirements_coverage.keys():
                        if req_id in content:
                            covered_requirements.add(req_id)
                            
                except Exception as e:
                    print(f"Error checking requirements in {file_path}: {e}")
        
        return covered_requirements, requirements_coverage
    
    def run_validation(self):
        """Run complete validation."""
        print("üîç Validating Comprehensive Test Implementation")
        print("=" * 60)
        
        all_valid = True
        
        # 1. Check file existence
        print("\nüìÅ Checking Test Files...")
        for file_path in self.test_files:
            exists = self.validate_file_exists(file_path)
            status = "‚úÖ" if exists else "‚ùå"
            print(f"  {status} {file_path}")
            if not exists:
                all_valid = False
        
        # 2. Check imports
        print("\nüì¶ Validating Imports...")
        for file_path in self.test_files:
            if os.path.exists(file_path):
                valid = self.validate_imports(file_path)
                self.validation_results["imports_valid"][file_path] = valid
                status = "‚úÖ" if valid else "‚ùå"
                print(f"  {status} {file_path}")
                if not valid:
                    all_valid = False
        
        # 3. Check test classes and methods
        print("\nüß™ Validating Test Classes...")
        total_classes = 0
        total_methods = 0
        
        for file_path in self.test_files:
            if os.path.exists(file_path):
                classes, methods = self.validate_test_classes(file_path)
                total_classes += len(classes)
                total_methods += methods
                
                print(f"  üìÑ {os.path.basename(file_path)}")
                print(f"    Classes: {len(classes)}, Methods: {methods}")
                
                for class_name in classes:
                    print(f"    ‚úÖ {class_name}")
        
        # 4. Check requirements coverage
        print("\nüìã Validating Requirements Coverage...")
        covered_reqs, all_reqs = self.validate_requirements_coverage()
        
        for req_id, description in all_reqs.items():
            status = "‚úÖ" if req_id in covered_reqs else "‚ùå"
            print(f"  {status} {req_id}: {description}")
            if req_id not in covered_reqs:
                all_valid = False
        
        # 5. Check configuration files
        print("\n‚öôÔ∏è Validating Configuration Files...")
        config_files = [
            "tests/conftest.py",
            "tests/pytest.ini", 
            "run_comprehensive_tests.py"
        ]
        
        for config_file in config_files:
            exists = os.path.exists(config_file)
            status = "‚úÖ" if exists else "‚ùå"
            print(f"  {status} {config_file}")
            if not exists:
                all_valid = False
        
        # 6. Summary
        print("\nüìä Validation Summary")
        print("=" * 40)
        print(f"Test Files: {len([f for f in self.test_files if os.path.exists(f)])}/{len(self.test_files)}")
        print(f"Test Classes: {total_classes}")
        print(f"Test Methods: {total_methods}")
        print(f"Requirements Covered: {len(covered_reqs)}/{len(all_reqs)}")
        
        # Overall status
        if all_valid:
            print("\nüéâ VALIDATION PASSED - All components implemented!")
            self.validation_results["overall_status"] = "passed"
        else:
            print("\n‚ùå VALIDATION FAILED - Some components missing!")
            self.validation_results["overall_status"] = "failed"
        
        return all_valid
    
    def generate_implementation_report(self):
        """Generate detailed implementation report."""
        report = {
            "validation_timestamp": str(datetime.now()),
            "test_implementation_status": self.validation_results,
            "recommendations": []
        }
        
        # Add recommendations based on validation results
        if self.validation_results["overall_status"] == "failed":
            report["recommendations"].extend([
                "Fix missing test files",
                "Resolve import errors", 
                "Implement missing test classes",
                "Add requirement coverage"
            ])
        else:
            report["recommendations"].append("Implementation is complete and ready for execution")
        
        # Save report
        with open("test_implementation_validation_report.json", "w") as f:
            import json
            json.dump(report, f, indent=2, default=str)
        
        print(f"\nüìÑ Detailed validation report saved to: test_implementation_validation_report.json")
        
        return report


def main():
    """Main validation entry point."""
    from datetime import datetime
    
    validator = TestImplementationValidator()
    
    # Run validation
    success = validator.run_validation()
    
    # Generate report
    validator.generate_implementation_report()
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()